{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageColor\n",
    "from utils.dataset import load_mask, load_bboxes, load_classIdxMap, load_stafflines\n",
    "from utils.metropolis_hastings import metropolis_hastings, binomial_distribution, propose_state, probability_matrix\n",
    "\n",
    "DATASET_PATH = os.path.join(\"..\", \"..\", \"datasets\", \"generated\")\n",
    "PNG_PATH = os.path.join(DATASET_PATH, \"png\")\n",
    "BBOX_PATH = os.path.join(DATASET_PATH, \"bbox\")\n",
    "\n",
    "AUG_PATH = os.path.join(DATASET_PATH, \"aug\")\n",
    "OUT_PATH = os.path.join(DATASET_PATH, \"unet_aug\")\n",
    "OUT_TRAIN_PATH_X = os.path.join(OUT_PATH, \"train\", \"x\")\n",
    "OUT_TRAIN_PATH_Y = os.path.join(OUT_PATH, \"train\", \"y\")\n",
    "OUT_TEST_PATH_X = os.path.join(OUT_PATH, \"test\", \"x\")\n",
    "OUT_TEST_PATH_Y = os.path.join(OUT_PATH, \"test\", \"y\")\n",
    "OUT_VALID_PATH_X = os.path.join(OUT_PATH, \"valid\", \"x\")\n",
    "OUT_VALID_PATH_Y = os.path.join(OUT_PATH, \"valid\", \"y\")\n",
    "\n",
    "with open(os.path.join(DATASET_PATH, \"classlist.json\")) as file:\n",
    "    classlist = json.load(file)\n",
    "    colormap = {c['color']: c['id'] for c in classlist}\n",
    "    colormap_inv = {c['id']: c['color'] for c in classlist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSystemParams(systems, idx, eps=0):\n",
    "    \n",
    "    sys = systems[idx]\n",
    "    x0 = max(0, sys[\"x\"] - eps)\n",
    "    y0 = max(0, sys[\"y\"] - eps)\n",
    "    x1 = x0 + sys[\"width\"] + 2 * eps\n",
    "    y1 = y0 + sys[\"height\"] + 2 * eps\n",
    "    factor = 256 / (sys[\"height\"] + 2 * eps)\n",
    "    \n",
    "    def map_box_coords(x, y, w, h):\n",
    "        x = int((x - x0) * factor)\n",
    "        y = int((y - y0) * factor)\n",
    "        w = int(w * factor)\n",
    "        h = int(h * factor)\n",
    "        return x, y, w, h\n",
    "    \n",
    "    def map_img(img, interpolation=cv2.INTER_NEAREST):\n",
    "        crop = img[y0:y1, x0:x1].astype(np.uint8)\n",
    "        cy = (y1 + y0) // 2\n",
    "        res = cv2.resize(crop, (int((x1 - x0) * factor), 256), interpolation=interpolation)\n",
    "        # res = img[cy - 128: cy + 128, x0:x1]\n",
    "        return res\n",
    "        \n",
    "    return map_box_coords, map_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset from augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing augmentation (0/10): dilation_all_k3, starting with index 1, 1 (train, test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:21<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing augmentation (1/10): dilation_all_k5, starting with index 769, 241 (train, test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:16<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing augmentation (2/10): dilation_stafflines_k3, starting with index 1537, 481 (train, test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing augmentation (3/10): dilation_stafflines_k5, starting with index 2305, 721 (train, test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:18<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing augmentation (4/10): dilation_xy_lines_k3, starting with index 3073, 961 (train, test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:18<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing augmentation (5/10): dilation_xy_lines_k5, starting with index 3841, 1201 (train, test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:20<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing augmentation (6/10): ideal, starting with index 4609, 1441 (train, test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:17<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing augmentation (7/10): staffline_interruptions, starting with index 5377, 1681 (train, test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:17<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing augmentation (8/10): staffline_thickness_variation, starting with index 6145, 1921 (train, test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:16<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing augmentation (9/10): staffline_y_variation, starting with index 6913, 2161 (train, test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:16<00:00,  1.55it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'plots'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 100\u001b[0m\n\u001b[0;32m     97\u001b[0m             mapping\u001b[39m.\u001b[39mappend([x_path, y_path, aug, unique_types[idx], x_out_path, y_out_path])\n\u001b[0;32m     99\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(mapping)\n\u001b[1;32m--> 100\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39mplots/augmented_dataset2.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 734\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    737\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    595\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'plots'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Preprocessing.dataset import listSubFiles, groupPaths\n",
    "\n",
    "\n",
    "paths = listSubFiles(AUG_PATH, depth=3)\n",
    "augmentations = groupPaths(paths, depth=2, return_group_names=True)[0]\n",
    "out_idx_train = 1\n",
    "out_idx_test = 1\n",
    "out_idx_valid = 1\n",
    "out_idx = 1\n",
    "\n",
    "# make output directories\n",
    "os.makedirs(OUT_TRAIN_PATH_X, exist_ok=True)\n",
    "os.makedirs(OUT_TRAIN_PATH_Y, exist_ok=True)\n",
    "os.makedirs(OUT_TEST_PATH_X, exist_ok=True)\n",
    "os.makedirs(OUT_TEST_PATH_Y, exist_ok=True)\n",
    "os.makedirs(OUT_VALID_PATH_X, exist_ok=True)\n",
    "os.makedirs(OUT_VALID_PATH_Y, exist_ok=True)\n",
    "\n",
    "# store original image name, augmentation, filenameX, filenameY\n",
    "mapping = []\n",
    "\n",
    "for idx, aug in enumerate(augmentations):\n",
    "    print(f\"Processing augmentation ({idx}/{len(augmentations)}): {aug}, starting with index {out_idx_train}, {out_idx_test} (train, test)\")\n",
    "    for s_idx in tqdm(range(1, 26)):\n",
    "        \n",
    "        sample_idx = f\"{s_idx:03d}\"\n",
    "\n",
    "        # for each sample:\n",
    "        x_path = os.path.join(AUG_PATH, aug, \"x\", f\"{sample_idx}.png\")\n",
    "        y_path = os.path.join(AUG_PATH, aug, \"y\", f\"{sample_idx}.png\")\n",
    "        orig_img_x = cv2.imread(x_path)\n",
    "        orig_img_y = cv2.imread(y_path)\n",
    "        \n",
    "        bboxes = load_bboxes(BBOX_PATH, sample_idx, img_shape=orig_img_x.shape)\n",
    "        systems = {bbox[\"id\"]: bbox for bbox in bboxes if bbox[\"type\"]==\"System\"}\n",
    "        unique_types = list(set([bbox[\"type\"] for bbox in bboxes if bbox[\"type\"] != \"System\"]))\n",
    "        \n",
    "        for idx, type in enumerate(unique_types):\n",
    "            \n",
    "            # get all bboxes of current type\n",
    "            tbs = [bbox for bbox in bboxes if bbox[\"type\"] == type]\n",
    "            if len(tbs)==0:\n",
    "                print(\"no box found for:\", type)\n",
    "                continue\n",
    "            \n",
    "            # pick random bbox\n",
    "            rand_idx = random.randint(0, len(tbs) - 1)\n",
    "            bbox = tbs[rand_idx]\n",
    "            cx = bbox[\"cx\"]\n",
    "            cy = bbox[\"cy\"]\n",
    "            w = bbox[\"width\"]\n",
    "            h = bbox[\"height\"]\n",
    "            \n",
    "            # map to system coordinates\n",
    "            map_box_coords, map_img = getSystemParams(systems, int(bbox[\"systemId\"]))\n",
    "            cx, cy, w, h = map_box_coords(cx, cy, w, h)\n",
    "            img_x = map_img(orig_img_x)\n",
    "            \n",
    "            # get frame centered around bbox center\n",
    "            x0 = cx - 128\n",
    "            x1 = cx + 128\n",
    "            if x0 < 0:\n",
    "                x0 = 0\n",
    "                x1 = 256\n",
    "            if x1 > img_x.shape[1]:\n",
    "                x1 = img_x.shape[1]\n",
    "                x0 = x1 - 256\n",
    "                \n",
    "            # split into train and test data\n",
    "            if s_idx <= 4:\n",
    "                out_path_x = OUT_VALID_PATH_X\n",
    "                out_path_y = OUT_VALID_PATH_Y\n",
    "                out_idx = out_idx_valid\n",
    "                out_idx_valid += 1\n",
    "            elif s_idx <= 20:\n",
    "                out_path_x = OUT_TRAIN_PATH_X\n",
    "                out_path_y = OUT_TRAIN_PATH_Y\n",
    "                out_idx = out_idx_train\n",
    "                out_idx_train += 1\n",
    "            else:\n",
    "                out_path_x = OUT_TEST_PATH_X\n",
    "                out_path_y = OUT_TEST_PATH_Y\n",
    "                out_idx = out_idx_test\n",
    "                out_idx_test += 1\n",
    "            \n",
    "            # crop and save x\n",
    "            img_x = img_x[:, x0:x1]\n",
    "            x_out_path = os.path.join(out_path_x, f\"{out_idx:04d}.png\")\n",
    "            cv2.imwrite(x_out_path, 255 - img_x)\n",
    "            \n",
    "            # crop and save y\n",
    "            img_y = map_img(orig_img_y)[:, x0:x1]\n",
    "            y_out_path = os.path.join(out_path_y, f\"{out_idx:04d}.png\")\n",
    "            cv2.imwrite(y_out_path, img_y)\n",
    "            \n",
    "            mapping.append([x_path, y_path, aug, unique_types[idx], x_out_path, y_out_path])\n",
    "\n",
    "df = pd.DataFrame(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_SPLIT_FILE = os.path.join(\"..\", \"..\", \"datasets\", \"generated\")\n",
    "os.makedirs(OUT_SPLIT_FILE, exist_ok=True)\n",
    "df.to_csv(os.path.join(OUT_SPLIT_FILE, \"split.csv\"), sep=';', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43afbf7b8c92a6397086dae0be21e5b6ecbdfbb1f0b6983c22cfbb740a73e7f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
